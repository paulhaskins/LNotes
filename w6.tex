\documentclass{report}

\input{preamble}
\input{macros}
\input{letterfonts}

%\usepackage[tagged, highstructure]{accessibility}
\usepackage{tocloft}
\usepackage{arydshln}




\begin{document}
\title{Linear Algebra I}
\author{Lecture Notes Provided by Dr.~Miriam Logan.}
\date{}
\maketitle
\tableofcontents
\newpage
\section{Properties of the Determinant}
\begin{enumerate}[label=(\roman*)]
  \item An $n \times n$  matrix $A$ is invertible if and only if $\left( \iff \right)  \text{det } A \neq 0$ 
          \pf{Proof:}{
         Let $R=$ row reduced echelon form of $ A$. The sequence of row operations that reduce  $A$ to $R$ merely involves multiplying $\text{det } A$ by a non-zero scalar
         \[
        \implies  \text{det }  A \neq 0 \iff \text{det }  R \neq 0
         .\] If $A $ is invertible the $R =I_n$ and so  \[
         \text{det } R =1 \implies \text{det }  A \neq 0
         .\] 
         If $A$ is not invertible then $R$ has a row of zeros and so  $\text{det } R =0 \implies \text{det }  A =0$
          }
          
  \item Suppose $A$ and $B$ are  $n \times n$  matrices 
          \[
          \text{det } \left( AB \right) = \left( \text{det } A \right) \left( \text{det } B \right) 
          .\] \pf{Proof:}{
         Suppose $A$ is an elementary matrix, $A=E$ 
         \begin{itemize}
                 \item If $ E$ results in replacement then
                         \begin{align*}
                                 \text{det } E =1\\
                                 \text{det } \left( EB \right) =\text{det }  B\\
                                 \text{ie } \text{det } \left( EB \right) =\left( \text{det } E \right) \left( \text{det } B \right) 
                         .\end{align*}
                 \item If $ E$ results in scaling a row by $\lambda$ 
                         \begin{align*}
                                 \text{det } E =\lambda\\
                                 \text{det } \left( EB \right) = \lambda \text{ det }  B\\
                                 \text{ie } \text{det } \left( EB \right) =\left( \text{det } E \right) \left( \text{det } B \right) 
                         .\end{align*}
                 \item If $ E$ results in interchanging two rows  
                         \begin{align*}
                                 \text{det } E =-1\\
                                 \text{det } \left( EB \right) = - \text{ det }  B\\
                                 \text{ie } \text{det } \left( EB \right) =\left( \text{det } E \right) \left( \text{det } B \right) 
                         .\end{align*}
         \end{itemize}
         Suppose $E_1,E_2,\ldots , E_p$  are a finite sequence of elementary matrices that reduce $A$ to reduced echelon form, $R$, then 
\begin{align*}
        E_p E_{p-1}\ldots E_2E_1A=R\\
        \text{ and so } A = E_1^{-1}E_2^{-1}\ldots E_{p-1}^{-1} E_{p}^{-1}R\\
\text{ using property \textbf{(i)} above we get that} \\
        \text{det } A = \text{det } \left( E_1^{-1} \right) \text{det } \left( E_2^{-1} \right) \ldots \text{det } \left( E_{p-1}^{-1} \right) 
\text{det } \left( E_{p}^{-1} \right) 
\text{det } \left( R \right) \\
.\end{align*}
$\implies$  To prove the statement we just need to show that $\text{det } \left(  AB\right) = \left( \text{det } A \right) \left( \text{det } B \right)$ when $ A$  is in reduced row echelon form, $ R$.\\
If $R = I_n$ then
 \[
\text{det } \left( R B \right) = \text{det }  B = \left( 1 \right) \left( \text{det } B \right) = \left( \text{det } R \right) \left( \text{det } B \right) 
.\] Otherwise, the last row of $ R$ is a row of zeros\\
$\implies$ The last row of $RB$ is a row of zeros and so $\text{det }  R = 0 = \text{det } \left(  RB\right) = \left( \text{det } R \right) \left( \text{det } B \right) $
 }
    \nt{The calculation of the determinant can be simplified by row reducing a matrix to echelon form. In a similar manner one can perform elementary column operations  in order to simplify the calculation of the determinant.\\
    In order to justify this we introduce the notion of the transpose of a matrix.}
  \end{enumerate}
  \dfn{Transpose of a Matrix :}{
  Suppose $A$ is a $m \times n$ matrix. The \underline{transpose} of $A$ (denoted by $A^{t}$ or $A^{T}$) is the $n \times m$ matrix whose $i^{\text{th}}$ column is the $i^{\text{th}}$ row of $A$
\[
\text{ i.e. } A \;=\;
\begin{bmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{bmatrix} \qquad A^{\mathsf T} \;=\;
\begin{bmatrix}
a_{11} & a_{21} & \cdots & a_{m1} \\
a_{12} & a_{22} & \cdots & a_{m2} \\
\vdots & \vdots & \ddots & \vdots \\
a_{1n} & a_{2n} & \cdots & a_{mn}
\end{bmatrix}
.\] i.e.  if the $\left( i,j \right) $ entry of $A$
 is $a_{ij}$ then the  $\left( i,j \right) $ entry of $A^{T}$ is $a_{ji}$ with $ \leq i \leq m$ and $1 \leq j \leq n$.}
  \section{Properties of the Transpose}
          Suppose $A$ and $B$ are matrices of  suitable  dimensions so that the operations below are defined in each case. Let $a_{ij}$, $b_{ij}$ be the $\left( i,j \right) $ entries of $A$ and $B$ respectively.
\begin{itemize}
        \item $\left( A+B \right) ^{t}=A^{t}+B^{t}$ \textit{proven in a tutorial }
        \item $\left(  A^{t     }\right)^{t}= A $, (swapping rows and columns of $A$  twice results in $A$)
        \item $ \left( AB \right) ^{t}=B^{t}A^{t}$ where $A =$  $m \times n$  and $B=$  $n \times p$.\\
                \pf{Proof}{\\
                $\left( i,j \right) $ entry of $AB = \sum\limits_{i=1}^{n}  a_{il}b_{lj}               $.\\
                $\left( i,j \right) $ entry of $\left( AB \right) ^{t} = \left( i,j \right) $ entry of $AB = \sum\limits_{i=1}^{n}  a_{jl}b_{li}               $.\\
                $\left( i,j \right) $ entry of $B^{t}A^{t}= $ ( $i^{\text{th}}$ row of $B^{t}$ )( $j^{\text{th}}$  col of $A^{t}$\\
                )= ( $i^{\text{th}}$  column of $B$)  ( $j^{\text{th}}$ row of $A$) \\
                = $\sum\limits_{i=1}^{n} b_{li} a_{jl}                $\\
                = $\left( i,j \right) $ entry of $\left(  AB\right) ^{t}$ \\
                $\implies \left( AB \right) ^{t}= B^{t}A^{t}$
                }
        \item If $A$ is invertible then $A ^{t}$ is invertible and $\left( A^{t } \right) ^{-1}= \left( A^{-1} \right) ^{t}$ 
                \pf{Proof:}{
                Suppose $A$ is invertible and let $A^{-1}$ be the inverse of $A$ $\implies  A A^{-1     } = I$. Taking transposes of both sides we get
                \begin{align*}
                        \left( A A^{-1} \right) ^{t}= I^{t}\\
                        \left( A^{-1} ^{t} \right) A ^{t}   =I^{t} \text{ \ldots using the third property}\\
                        \implies A^{t} \text{ is invertible and } \left( A ^{t} \right) td-1 = \left( A ^{-1} \right)  ^{t}
                .\end{align*} 
                }
        \item $ \text{det } \left( A^{t} \right) = \text{det } A $ 
                \pf{Proof:}{
               \[
               \text{det } A = \sum\limits_{\sigma}^{} \text{sgn } \sigma a_{1\sigma \left( 1 \right) }\sigma a_{2\sigma \left( 2 \right) }\ldots 
\sigma a_{n\sigma \left( n \right) }
               .\]  
\textbf{Note:} If \[
\sigma = \begin{bmatrix}
1 & 2 & \ldots & n\\
\sigma \left( 1 \right)  & \sigma \left(  2 \right)  & \ldots  & \sigma \left( n \right)  \\
\end{bmatrix} \qquad \text{then } \sigma ^{-1}=\begin{bmatrix}
\sigma \left( 1 \right)  & \sigma \left(  2 \right)  & \ldots  & \sigma \left( n \right)  \\
1 & 2 & \ldots & n\\
\end{bmatrix} 
.\]  $\text{sgn }  \sigma = \text{sgn }  \sigma ^{-1}$ since swapping rows doesn't change the number of inversions.\\
Now, in the formula for the determinant we sum over all the inverses $\sigma ^{-1}$ (gives the same sum since every permutation is invertible ) and so,
\begin{align*}
        \text{det } A = \sum\limits_{\sigma ^{-1}}^{d} \text{sgn }  \sigma ^{-1} a _{\sigma \left( 2 \right) 2},a _{\sigma \left( 1 \right) 1},\ldots a _{\sigma \left( n \right) n}\\
= \sum\limits_{\sigma ^{-1}}^{d} \text{sgn }  \sigma ^{-1} a _{\sigma \left( 2 \right) 2},a _{\sigma \left( 1 \right) 1},\ldots
a _{\sigma \left( n \right) n}\\
=\text{det }  A ^{t}
        
.\end{align*}
                }
                
\end{itemize}
\section{The equivalence of definitions of the determinant }
\dfn{Determinant of an $n \times n$  matrix :}{

Suppose $A$ is an  $n \times n$ matrix  with entry $a_{ij} $ in the $\left( i,j \right) $ position. we have to equivalent definitions for the determinant of $A$.
 \begin{itemize}
        \item \[\text{det } A = \sum\limits_{\sigma}^{} \text{sgn } \left( \sigma  \right) a_{1\sigma \left( 1 \right) }\sigma a_{2\sigma \left( 2 \right) }\ldots 
\sigma a_{n\sigma \left( n \right) }
.\] where the sum is over all permutations of $n$ elements.
\item (Expansion by minors) Recall $A^{ij}$ is the  $\left( n-1  \right) \times \left( n-1 \right) $  matrix obtained by deleting the $i^{\text{th}}$ row and the $i^{\text{th}}$ column of $A$.\\
        We can define $ \text{det } A$ inductively as follows: 
        \[
                \text{det } \left[ a \right] =a \text{ for } 1\times 1 \text{ matrices } \\
                \text{det } A = \sum\limits_{j=1}^{n} a_{ij} \left( -1 \right) ^{i+j} \text{det } A^{ij} \text{ for } n \times n \text{ matrices with } n > 1     
        .\]                                            
                     
                         
                                                                            
\end{itemize}
}
 \textbf{Note:}  Since $ \text{det } A = \text{det } A^{t}$  , the second definition can be written as 
\[
\text{det } A = \sum\limits_{j=1}^{n} a_{ji} \left( -1 \right) ^{i+j} \text{det } A^{ij} \text{ (expansion across $1^{\text{st}}$ row).}
.\]    
 
\pf{Proof:}{
  Assume $ \text{det } A = \sum\limits_\sigma{}^{} \text{sgn } \sigma a_{1\sigma \left( 1 \right) }\sigma a_{2\sigma \left( 2 \right) }\ldots a_{n\sigma \left( n \right) }$. Each term in the sum contains an entry from row $ 1$\\
  Fix $ k \in \{ 1,2,3,\ldots,n \} $ and gather all the terms in the sum that contain $ a_{1k}$ i.e. all terms such that $\sigma \left( 1 \right) =k$.\\
  Factor out $ a_{1k}$ from these terms and we get
  \[
          a_{1k} \sum\limits_{\tilde{\sigma} }^{} \text{sgn } \tilde{\sigma} a_{2\tilde{\sigma} \left( 2 \right) }\ldots a_{n\tilde{\sigma}\left( n \right) }
  .\]             
  here we are summing over all permutations $\tilde{\sigma}$ where  $ \tilde{\sigma\left( 1 \right) }=k$ \\
  There are $ \left( n-1 \right) !$ terms in this sum\\
  (after fixing where $ 1$ goes, there are $ \left( n-1 \right) $ objects remaining that may be permuted and there are $ \left( n-1 \right) !$ ways of permuting them)\\
  \\
  In each product $ a_{2\tilde{\sigma} \left( 2 \right) }\ldots a_{n\tilde{\sigma}\left( n \right) }$ there is no entry from row $ 1$ or coulumn $ k$ of $ A$. In each product $ a_{2\tilde{\sigma} \left( 2 \right) }\ldots a_{n\tilde{\sigma}\left( n \right) }$ there is exactly one entry from each of ther rows of $ A^{1k}$\\
  \textit{(the first su bscript going from $ 2$ to $ n$  takes care of that )} \\
  and exactly one entry from each of the columns of $ A^{1k}$\\
  \textit{(the bijectivity of the permuatation $ \sigma$ ensures that every term from $ 1$ to $ n$ except $ k$ appears as a second subscript )}\\
  Hence the terms of the sum coinside with the terms in the definition of $ \text{det } A^{1k}$, we just need to adjust the signs.\\
  \\
In order to express $\sum_{\tilde{\sigma}}
      \operatorname{sgn}(\tilde{\sigma})\,
      a_{2,\tilde{\sigma}(2)}
      \cdots
      a_{n,\tilde{\sigma}(n)}$ as a determinant of an $\left( n-1 \right) \times \left( n-1 \right) $ matrix we need to view the permutations $\tilde{\sigma}$ as permutations of the set $\{ 2,3,\ldots,n \}$ which we do by ignoring the first  column of $ \tilde{ \sigma}   \binom{1}{k}$.\\
      \\
      Let $ \tilde{ \alpha}   $ be the permutation of $ n-1$ elements  $ \{ 2,3,\ldots,n \}$ such that $ \tilde{ \alpha}   \left( j \right) = \tilde{ \sigma}   \left( j \right) $. Namely the number of inversions in $ \tilde{ \alpha}   $ is the same as the number of inversions in $ \tilde{ \sigma}   $ and so $ \text{sgn } \tilde{ \alpha}   =\text{sgn } \tilde{ \sigma}   $.\\
      \textit{Since $ \binom{1}{k}$ induces no inversion in the top row and $ k-1$ in the bottom row, since there are $ k-1$ terms less that are less than $ k$.}\\
 \begin{align*}
   \implies \text{sgn } \left( \tilde{ \alpha}   \left( -1 \right) ^{\text{\# of inversions in } \tilde{ \alpha}   } \right)\\
   &= \left( -1 \right) ^{\text{\# of inversions in } \tilde{ \sigma}   }\\
   &= \text{sgn } \tilde{ \sigma}   \left( -1 \right) ^{k+1}\\
   sgn \left( \tilde{ \alpha } \right) &= sgn \left( \tilde{ \sigma}    \right)  \left( -1 \right) ^{k+1}   
 .\end{align*}
            \\
Hence, all the terms in the sum, $ \text{det } A$ that contain 
\begin{align*}
        a_{1k} = a_{1k} \sum\limits_{  \tilde{ \alpha}   }^{} \left( -1 \right) ^{k+1} \text{sgn } \tilde{ \alpha}  a_{2,\tilde{ \alpha}   \left( 2 \right) }\ldots a_{n,\tilde{ \alpha}   \left( n \right) }\\
        = a_{1k} \left( -1 \right) ^{k+1} \text{det } A^{1k}\\
.\end{align*}
Summing over all $ k$ we get:
\[
        \text{det } A = \sum\limits_{k=1}^{n} a_{1k} \left( -1 \right) ^{1+k} \text{det } A^{1k}
\]
This is an expansion across the first row of $ A$. We could express the determinant as an expansion across any row or column of $ A$, for example, across the $ j^{\text{th}}$ row  by swapping $1^{\text{st}}$ and $j^{\text{th}}$ rows of $ A$ and adjusting  the formula
\[
        \text{det } A = \left( -1 \right) \text{det } \tilde{ A}   \text{ where } \tilde{ A}   \text{ is the matrix obtained by swapping the $1^{\text{st}}$ and $j^{\text{th}}$ rows} 
                              
                      \] \[
                                A \;=\;
\begin{bmatrix}
a_{11} & a_{12} & a_{13} & \cdots & a_{1n}\\
a_{21} & a_{22} & a_{23} & \cdots & a_{2n}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
a_{j1} & a_{j2} & a_{j3} & \cdots & a_{jn}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & a_{n3} & \cdots & a_{nn}
\end{bmatrix}
\qquad
\widetilde{A} \;=\;
\left[
\begin{array}{ccccc}
a_{j1} & a_{j2} & a_{j3} & \cdots & a_{jn}\\
a_{21} & a_{22} & a_{23} & \cdots & a_{2n}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
a_{11} & a_{12} & a_{13} & \cdots & a_{1n}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & a_{n3} & \cdots & a_{nn}
\end{array}
\right]
\quad
\left.
\begin{array}{c}
\\[-1.2em]\\ \\ \\ \\[-0.6em]
\end{array}
\right\}
\; \text{\(j^{\text{th}}\) row}
                       \]     \\
        \begin{align*}
                \implies \text{det } A = \left( -1 \right) \sum\limits_{k=1}^{n} a_{ji} \text{det } \tilde{ A }   ^{1i}\\
                = \sum\limits_{k=1}^{n} \left( -1 \right) ^{i+2} a_{ji} \text{det } \tilde{ A }   ^{1i}\\
        .\end{align*}
        \nt{
                \begin{align*}
                        \text{det } \tilde{ A }   ^{11}= \text{det } \!
\left[
\begin{array}{cccc}
a_{22} & a_{23} & \cdots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{12} & a_{13} & \cdots & a_{1n}\\
\vdots & \vdots &        & \vdots\\
a_{n2} & a_{n3} & \cdots & a_{nn}
\end{array}
\right]
\quad
\left.
\begin{array}{c}
\\[-1.2em] \\ \\ \\ \\[-0.6em]
\end{array}
\right\}
\;(j-1)^{\text{th}}\text{ row}  \\
=    \,(-1)^{\,j-2}\,
\det
\begin{bmatrix}
a_{12} & a_{13} & \cdots & a_{1n}\\
a_{22} & a_{23} & \cdots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n2} & a_{n3} & \cdots & a_{nn}
\end{bmatrix}
\quad
\left.
\begin{array}{c}
\\[-1.2em] \\ \\ \\ \\[-0.6em]
\end{array}
\right\}
\; j^{\text{th}}\ \text{row missing}
                .\end{align*}
                \[
                        \text{ i.e. }  \text{det } \tilde{ A }   ^{11}= \left( -1 \right) ^{j-2} \text{det } A^{j 1}
                \]                                     \[
                        \text{ and in general }  \text{det } \tilde{ A }   ^{1i} = \left( -1 \right) ^{j-2} \text{det } A^{ji}
                \]
        }
\begin{align*}
        \text{ Hence, } \text{det } A = \sum\limits_{k=1}^{n} \left( -1 \right) ^{i+2} a_{ji} \left( -1 \right) ^{j-2} \text{det } A^{ji}\\
        = \sum\limits_{k=1}^{n} a_{ji} \left( -1 \right) ^{i+j} \text{det } A^{ji} \\
.\end{align*}
}       
  This is the cofactor expansion across the $j^{\text{th}}$  row of  $A $.
  \ex{}{
          \textit{Find $ \text{det } A$ where} $ A=\begin{bmatrix}
  3 & 1 & 5\\
  1 & -2 & 0\\
  -1 & 2 & 3\\
  \end{bmatrix}$       \\
  \textbf{Solution:} \\
  Using cofactor expansion across the first row we get
  \[
          3 \text{ det } \begin{bmatrix}
          -2 & 0\\
          2 & 3\\
          \end{bmatrix} - 1 \text{ det } \begin{bmatrix}
          1 & 0\\
          -1 & 3\\
          \end{bmatrix} + 5 \text{ det } \begin{bmatrix}
          1 & -2\\
          -1 & 2\\
          \end{bmatrix}
  \]
  \[
          = 3\left( -6 \right) -1\left( 3 \right) +5\left( 0 \right) = -18 -3 +0 = -21
  \]
  Using cofactor expansion across the second row we get
        \[
                -1 \text{ det } \begin{bmatrix}
                1 & 5\\
                -1 & 3\\
                \end{bmatrix} +2 \text{ det } \begin{bmatrix}
                3 & 5\\
                -1 & 3\\
                \end{bmatrix} +0\left( \text{ det } \begin{bmatrix}
                3 & 1\\
                -1 & 2\\
                \end{bmatrix} \right)
        \]
        \[
                = -1\left( 3 -10 \right) +2\left( 9 +5 \right) +0 = 7-2\left( 14 \right)  = -21
        \]
        Using cofactor expansion across the third row we get
        \[
                -1 \text{ det } \begin{bmatrix}
                1 & 5\\
                1 & -2\\
                \end{bmatrix} +2 \text{ det } \begin{bmatrix}
                3 & 5\\
                1 & -2\\
                \end{bmatrix} +3\left( \text{ det } \begin{bmatrix}
                3 & 1\\
                1 & -2\\
                \end{bmatrix} \right)
        \]
        \[
                = -1\left(  10\right) -2\left( -5 \right) +3\left( -6 -1 \right) = -10+10= -21
        \]
        Using cofactor expansion across the first column we get
        \[
                3 \text{ det } \begin{bmatrix}
                -2 & 0\\
                2 & 3\\
                \end{bmatrix} +1 \text{ det } \begin{bmatrix}
                1 & 5\\
                -1 & 3\\
                \end{bmatrix} -1 \text{ det } \begin{bmatrix}
                1 & -2\\
                -1 & 2\\
                \end{bmatrix}
        \]
            \[
                = 3\left( -6 \right) -1\left( 3 -10 \right) -1\left( 10 \right) = -18 +7 -10 = -21
            \]
        Using cofactor expansion across the second column we get
                 \[
                         -1 \text{det } \begin{bmatrix}
                         1 & 0\\
                         -1 & 3\\
                         \end{bmatrix} -2 \text{det } \begin{bmatrix}
                         3 & 5\\
                         -1 & 3\\
                         \end{bmatrix} -2 \text{det } \begin{bmatrix}
                         3 & 5\\
                         1 & 0\\
                         \end{bmatrix}
                 \]
                        \[
                                = -1\left( 3 \right) -2\left( 9 +5 \right) -2\left( -5 \right) = -3-28-10 = -21
                        \]
                        Using cofactor expansion across the third column we get
                        \[
                                5 \text{det } \begin{bmatrix}
                                1 & -2\\
                                -1 & 2\\
                                \end{bmatrix} +0\left( \text{det } \begin{bmatrix}
                                3 & 1\\
                                -1 & 2\\
                                \end{bmatrix} \right) +3\left( \text{det } \begin{bmatrix}
                                3 & 1\\
                                1 & -2\\
                                \end{bmatrix} \right)
                        \]
                        \[
                                = 5\left( 0 \right) -0\left( 7 \right) +3\left(  -7 \right) = 0 +0 3\left( -7 \right)  = -21
                        \]
        }
\section{Another Method of Finding the Inverse of a Matrix}\\
\textit{First we need some definitions.}\\
Suppose $A$ is an $n \times n$ matrix.\\
\dfn{Minor of a Matrix :}{
The \underline{minor $ A^{ij}$} is the $ \left( n-1 \right) \times \left( n-1 \right) $ matrix obtained by deleting the $i^{\text{th}}$ row and the $j^{\text{th}}$ column of $A$.\\ 
}
\dfn{Matrix of Minors :}{
The \underline{matrix of minors}, $ M$, is the $n \times n$ matrix whose $\left( i,j \right) $ entry is the minor $ M_{ij}= \text{det } A^{ij}$ of $A$.
}
\dfn{Cofactor Matrix:}{
The \underline{cofactor}, $ C_{ij}$ of the martrix $A$ is defined as the signed determinant of the minor $ A^{ij}$, i.e. $ C_{ij}= \left( -1 \right) ^{i+j}M_{ij}= \left( -1 \right) ^{i+j} \text{det } A$.
}
\dfn{Adjugate of a Matrix :}{
The \underline{adjugate} of $A$, denoted by $ \text{adj}  \left( A \right) $ is the transpose of the cofactor matrix, i.e. $ \text{adj } \left( A \right) = C^{T}$
}
  \thm{Inverse of a Matrix :}{
 \begin{align*}
         A \left( \text{ adj } A \right) = \left( \text{ adj } A \right) \left( A \right) = \left( \text{det } A \right) I_n\\
         \text{ In particular }  \left( \frac{1}{  \text{det } A} \right) \left( \text{ adj } A \right) \left( A \right) = I_n\\
         \text{ i.e. } A^{-1} = \left( \frac{1}{  \text{det } A} \right) \left(\text{ adj } A \right)\\
 .\end{align*}
 }
  \textit{We will prove this theorem in due course, for now we will use it to calculate some inverses.}\\ 
  \ex{}{
\textit{Let}
\[
A=\begin{bmatrix}
 1 & 0 & -2\\
 -3 & 1 &  4\\
 2 & -3 &  4
\end{bmatrix}.
\]
\begin{enumerate}[label=(\roman*)]

%-------------------------------------------------------------
\item \emph{Matrix of minors}
\[
\begin{aligned}
M_{11}&=\det\!\begin{bmatrix} 1 &  4\\-3 & 4\end{bmatrix}=16,
&M_{12}&=\det\!\begin{bmatrix}-3 & 4\\ 2 & 4\end{bmatrix}=-20,\\
M_{13}&=\det\!\begin{bmatrix}-3 & 1\\ 2 &-3\end{bmatrix}=7,
&M_{21}&=\det\!\begin{bmatrix} 0 &-2\\-3 & 4\end{bmatrix}=-6,\\
M_{22}&=\det\!\begin{bmatrix} 1 &-2\\ 2 & 4\end{bmatrix}=8,
&M_{23}&=\det\!\begin{bmatrix} 1 & 0\\ 2 &-3\end{bmatrix}=-3,\\
M_{31}&=\det\!\begin{bmatrix} 0 &-2\\ 1 & 4\end{bmatrix}=2,
&M_{32}&=\det\!\begin{bmatrix} 1 &-2\\-3 & 4\end{bmatrix}=-2,\\
M_{33}&=\det\!\begin{bmatrix} 1 & 0\\-3 & 1\end{bmatrix}=1.
\end{aligned}
\]
Hence
\[
M=\begin{bmatrix}
16 & -20 &  7\\
-6 &   8 & -3\\
 2 &  -2 &  1
\end{bmatrix}.
\]

%-------------------------------------------------------------
\item \emph{Cofactor matrix}
\[
C=\begin{bmatrix}
16 & 20 & 7\\
 6 &  8 & 3\\
 2 &  2 & 1
\end{bmatrix}.
\]

%-------------------------------------------------------------
\item \emph{Determinant}
\[
\det A
  =1(4+12) +(-2)(7)        % –2 × 7
  =16-14
  =2.
\]

%-------------------------------------------------------------
\item \emph{Inverse}
\[
\operatorname{adj}A=C^{\mathsf T}=
\begin{bmatrix}
16 &  6 & 2\\
20 &  8 & 2\\
 7 &  3 & 1
\end{bmatrix},\qquad
A^{-1}=\frac{1}{2}\operatorname{adj}A=
\begin{bmatrix}
 8 & 3 & 1\\
10 & 4 & 1\\
\frac72 & \frac32 & \frac12
\end{bmatrix}.
\]
\end{enumerate}
}

%=====================================================================
\ex{}{
\textit{Use the theorem to show that the inverse of}
\[
A=\begin{bmatrix}
a & b\\
c & d
\end{bmatrix}
\quad\textit{is}\quad
A^{-1}= \frac{1}{ad-bc}
\begin{bmatrix}
 d & -b\\
 -c&  a
\end{bmatrix}.
\]

\textbf{Solution.}\\[2pt]
Minors: \(M_{11}=d,\;M_{12}=c,\;M_{21}=b,\;M_{22}=a\).  
Thus
\[
C=\begin{bmatrix}
 d & -c\\
 -b&  a
\end{bmatrix},
\qquad
\operatorname{adj}A=C^{\mathsf T}
      =\begin{bmatrix}
          d & -b\\
         -c &  a
        \end{bmatrix}.
\]
Because \(\det A=ad-bc\),
\[
A^{-1}=\frac{1}{\det A}\,\operatorname{adj}A
      =\frac{1}{ad-bc}
        \begin{bmatrix}
          d & -b\\
         -c &  a
        \end{bmatrix}.
\]
}
\pf{Proof}{ \underline{Proving that} $ A^{-1} = \left( \frac{1}{ \text{ det } A} \right) \left( \text{ adj } A \right)  $ \\
Suppose $ A = \begin{bmatrix}
a_{11} & a_{12} & \ldots & a_{1n}\\
a_{21} & a_{22} & \ldots & a_{2n}\\
\vdots & \vdots & \vdots & \vdots\\
 a_{ n1}& a_{ n 2} & \ldots & a_{ n n}\\
\end{bmatrix}$  \\We have that 
\begin{align*}
           \text{ det } A = \sum\limits_{j=1}^{n} \left( -1 \right) ^{i+j} a_{ij} \text{ det } A^{ij} \\                                           = \sum\limits_{j=1}^{n} a_{ij} C_{ij} \text{ (where } C_{ij} \text{ is the cofactor of } A \text{ )}\\
           = a_{i1} C_{i1} + a_{i2} C_{i2} + \ldots + a_{in} C_{in}\\
.\end{align*}
\textbf{Note:} $ a_{ i 1} C_{j 1} + a_{i 2}C_{j 2}+ \ldots + a_{ i n} C _{j n} =0$ if $ i \neq j$.\\
\textit{Why?} Let $ A^{1}$ be the martrix obtained from $ A$ by replacing the $j^{\text{th}}$ row with the $i^{\text{th}}$ row.\\
   \[
A^{\,1}=
\left[
\begin{array}{cccc}
a_{11} & a_{12} & \cdots & a_{1n}\\[6pt]
\vdots & \vdots &        & \vdots\\[6pt]
a_{i1} & a_{i2} & \cdots & a_{in}\\[6pt]
\vdots & \vdots &        & \vdots\\[6pt]
a_{j1} & a_{j2} & \cdots & a_{jn}\\[6pt]
\vdots & \vdots &        & \vdots\\[6pt]
a_{n1} & a_{n2} & \cdots & a_{nn}
\end{array}
\right]
\qquad
\begin{array}{@{}l@{}}
\\[10pt]              % ← skip two rows
\leftarrow\; \text{$i$-th row}\\[24pt]
\leftarrow\; \text{$j$-th row}
\end{array}
\]
 \[
\text{ det } A^{1} = a_{i1} C_{j 1} + a_{i2} C_{j 2} + \ldots + a_{in} C_{j n} \quad\text{ ( expanding across the $j^{\text{th}}$ row )}
.\] 
But notice $ A^{1}$ has tow equal rows $ \implies \text{ det } A^{1}=0$                   \\
Hence, $ a_{i1} C_{j 1} + a_{i2} C_{j 2} + \ldots + a_{in} C_{j n} = \begin{cases}
        0 & \text{if } i\neq j \\
        \text{ det } A & \text{if } i=j
\end{cases} 
$
Notice this looks like a dot product.\\
i.e. $ \langle a_{ i 1}, a _{i 2}, \ldots , a_{ i n}  \rangle  \langle C_{ j 1 }, C_{ j 2}, \ldots , C_{ j n}  \rangle  =  \begin{cases}
        0 & \text{if } i\neq j \\
        \text{ det } A & \text{if } i=j
\end{cases}
$ 
which can be viewed as the $ \left( i,j \right) $  entry of the a matrix product $ A\cdot C^{T}$.
\[
= \begin{bmatrix}
a_{11} & a_{12} & \ldots & a_{1n}\\
a_{21} & a_{22} & \ldots & a_{2n}\\
\vdots & \vdots & \vdots & \vdots\\
a_{21} & a_{22} & \ldots & a_{2n}\\
\vdots & \vdots & \vdots & \vdots\\
 a_{ n1}& a_{ n 2} & \ldots & a_{ n n}\\
\end{bmatrix}      \begin{bmatrix}
c_{11} & c_{12} & \ldots & c_{1n}\\
c_{21} & c_{22} & \ldots & c_{2n}\\
\vdots & \vdots & \vdots & \vdots\\
\vdots & \vdots & \vdots & \vdots\\
\vdots & \vdots & \vdots & \vdots\\
 c_{ 1 n}& a_{ 2 n} & \ldots & a_{ n n}\\
\end{bmatrix} =      \begin{bmatrix}
\text{ det } A &  0& \ldots & 0\\
0 & \text{ det } A & \ldots & 0\\
\vdots & \vdots & \vdots & \vdots\\
\vdots & \vdots & \vdots & \vdots\\
\vdots & \vdots & \vdots & \vdots\\
 0& 0 & \ldots & \text{ det } A\\
\end{bmatrix} 
.\]      i.e. 
\begin{align*}
        A \cdot C^{T} = \left( \text{ det } A \right) I_n\\
        \implies \left( A \right) \left( \text{ adj } A \right) = \text{ det } A \left( I_n \right) \\
        \implies A^{-1} = \left( \frac{1}{ \text{ det } A} \right) \left( \text{ adj } A \right)\\
.\end{align*}
}


 
 
  



                                          
  
\end{document}                                          
